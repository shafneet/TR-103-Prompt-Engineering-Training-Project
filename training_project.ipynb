{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d62697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.93.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: streamlit in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.48.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.0.0)\n",
      "Requirement already satisfied: reportlab in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (3.6.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\simra\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\simra\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.4.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai streamlit pytesseract pillow reportlab speechrecognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64276082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.48.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.0.0)\n",
      "Requirement already satisfied: reportlab in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.4.3)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.14.3)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\simra\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (1.8.2)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.2.1)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\simra\\appdata\\roaming\\python\\python311\\site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (5.29.5)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (8.4.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from streamlit) (6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.175.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit google-generativeai python-dotenv pytesseract pillow reportlab SpeechRecognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b1ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.175.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\simra\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade google-generativeai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c51087cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Available Models:\n",
      "ðŸ”¹ models/embedding-gecko-001 â†’ ['embedText', 'countTextTokens']\n",
      "ðŸ”¹ models/gemini-1.5-pro-latest â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-pro-002 â†’ ['generateContent', 'countTokens', 'createCachedContent']\n",
      "ðŸ”¹ models/gemini-1.5-pro â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-flash-latest â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-flash â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-flash-002 â†’ ['generateContent', 'countTokens', 'createCachedContent']\n",
      "ðŸ”¹ models/gemini-1.5-flash-8b â†’ ['createCachedContent', 'generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-flash-8b-001 â†’ ['createCachedContent', 'generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-1.5-flash-8b-latest â†’ ['createCachedContent', 'generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-2.5-pro-preview-03-25 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash-preview-05-20 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash-lite-preview-06-17 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-pro-preview-05-06 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-pro-preview-06-05 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-pro â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-exp â†’ ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-001 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-exp-image-generation â†’ ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-lite-001 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-lite â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-preview-image-generation â†’ ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-lite-preview-02-05 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-lite-preview â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-pro-exp â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-pro-exp-02-05 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-exp-1206 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-thinking-exp-01-21 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-thinking-exp â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-thinking-exp-1219 â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash-preview-tts â†’ ['countTokens', 'generateContent']\n",
      "ðŸ”¹ models/gemini-2.5-pro-preview-tts â†’ ['countTokens', 'generateContent']\n",
      "ðŸ”¹ models/learnlm-2.0-flash-experimental â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3-1b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3-4b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3-12b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3-27b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3n-e4b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemma-3n-e2b-it â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-2.5-flash-lite â†’ ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash-image-preview â†’ ['generateContent', 'countTokens']\n",
      "ðŸ”¹ models/embedding-001 â†’ ['embedContent']\n",
      "ðŸ”¹ models/text-embedding-004 â†’ ['embedContent']\n",
      "ðŸ”¹ models/gemini-embedding-exp-03-07 â†’ ['embedContent', 'countTextTokens', 'countTokens']\n",
      "ðŸ”¹ models/gemini-embedding-exp â†’ ['embedContent', 'countTextTokens', 'countTokens']\n",
      "ðŸ”¹ models/gemini-embedding-001 â†’ ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "ðŸ”¹ models/aqa â†’ ['generateAnswer']\n",
      "ðŸ”¹ models/imagen-3.0-generate-002 â†’ ['predict']\n",
      "ðŸ”¹ models/imagen-4.0-generate-preview-06-06 â†’ ['predict']\n",
      "ðŸ”¹ models/imagen-4.0-ultra-generate-preview-06-06 â†’ ['predict']\n",
      "ðŸ”¹ models/imagen-4.0-generate-001 â†’ ['predict']\n",
      "ðŸ”¹ models/imagen-4.0-ultra-generate-001 â†’ ['predict']\n",
      "ðŸ”¹ models/imagen-4.0-fast-generate-001 â†’ ['predict']\n",
      "ðŸ”¹ models/veo-2.0-generate-001 â†’ ['predictLongRunning']\n",
      "ðŸ”¹ models/veo-3.0-generate-preview â†’ ['predictLongRunning']\n",
      "ðŸ”¹ models/veo-3.0-fast-generate-preview â†’ ['predictLongRunning']\n",
      "ðŸ”¹ models/veo-3.0-generate-001 â†’ ['predictLongRunning']\n",
      "ðŸ”¹ models/veo-3.0-fast-generate-001 â†’ ['predictLongRunning']\n",
      "ðŸ”¹ models/gemini-2.5-flash-preview-native-audio-dialog â†’ ['countTokens', 'bidiGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.5-flash-exp-native-audio-thinking-dialog â†’ ['countTokens', 'bidiGenerateContent']\n",
      "ðŸ”¹ models/gemini-2.0-flash-live-001 â†’ ['bidiGenerateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-live-2.5-flash-preview â†’ ['bidiGenerateContent', 'countTokens']\n",
      "ðŸ”¹ models/gemini-2.5-flash-live-preview â†’ ['bidiGenerateContent', 'countTokens']\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# checking the models\n",
    "#####################\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "print(\"âœ… Available Models:\")\n",
    "for model in genai.list_models():\n",
    "    print(f\"ðŸ”¹ {model.name} â†’ {model.supported_generation_methods}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a529a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "#importing the data\n",
    "#########################\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Gemini API Key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adb95e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 2: Gemini Functions\n",
    "# ==============================\n",
    "def generate_questions(role):\n",
    "    \"\"\"Generate interview questions using Gemini\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an interviewer. Generate 1 technical or behavioral interview questions\n",
    "    for a candidate applying for {role}. Only return the list of questions as plain text, no explanation.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# def evaluate_answer(question, answer):\n",
    "#     \"\"\"Evaluate candidate answer using Gemini\"\"\"\n",
    "#     eval_prompt = f\"\"\"\n",
    "#     Evaluate this interview response:\n",
    "#     Question: {question}\n",
    "#     Answer: {answer}\n",
    "\n",
    "#     Provide:\n",
    "#     1. Score out of 10\n",
    "#     2. Strengths\n",
    "#     3. Weaknesses\n",
    "#     4. Improvement Tips\n",
    "#     \"\"\"\n",
    "#     model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
    "#     response = model.generate_content(eval_prompt)\n",
    "#     return response.text\n",
    "\n",
    "def evaluate_answer(question, answer):\n",
    "    \"\"\"Evaluate candidate answer using Gemini\"\"\"\n",
    "\n",
    "    # Ensure inputs are not empty\n",
    "    if not question.strip() or not answer.strip():\n",
    "        return \"âš ï¸ Question or Answer is empty. Please provide valid input.\"\n",
    "\n",
    "    # Prompt to send to Gemini\n",
    "    eval_prompt = f\"\"\"\n",
    "    Evaluate this interview response:\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "\n",
    "    Provide:\n",
    "    1. Score out of 10\n",
    "    2. Strengths\n",
    "    3. Weaknesses\n",
    "    4. Improvement Tips\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize model\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.generate_content(eval_prompt)\n",
    "\n",
    "    # Safely access model output\n",
    "    if response.candidates and response.candidates[0].content.parts:\n",
    "        return response.candidates[0].content.parts[0].text\n",
    "    else:\n",
    "        return \"âš ï¸ No feedback was generated by the model. Try rephrasing your answer.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc902320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 3: Input Modes\n",
    "# ==============================\n",
    "def get_text_input():\n",
    "    return input(\"Type your answer: \")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice and convert to text\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"ðŸŽ¤ Speak now...\")\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        return r.recognize_google(audio)\n",
    "    except:\n",
    "        return \"Could not understand audio.\"\n",
    "\n",
    "def get_image_input():\n",
    "    \"\"\"Extract text from image using OCR\"\"\"\n",
    "    image_path = input(\"Enter image file path: \")\n",
    "    img = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8607d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# STEP 4: PDF Report\n",
    "# ==============================\n",
    "# def create_report(filename, feedback):\n",
    "#     c = canvas.Canvas(filename)\n",
    "#     c.drawString(100, 750, \"AI Interview Feedback Report\")\n",
    "#     y = 720\n",
    "#     for line in feedback.split(\"\\n\"):\n",
    "#         c.drawString(100, y, line)\n",
    "#         y -= 20\n",
    "#     c.save()\n",
    "#     print(f\"âœ… Report saved as {filename}\")\n",
    "\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from textwrap import wrap\n",
    "\n",
    "def create_report(filename, feedback):\n",
    "    c = canvas.Canvas(filename, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Margins\n",
    "    left_margin = 50\n",
    "    top_margin = height - 50\n",
    "    \n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(left_margin, top_margin, \"AI Interview Feedback Report\")\n",
    "    \n",
    "    # Prepare text object\n",
    "    text = c.beginText()\n",
    "    text.setTextOrigin(left_margin, top_margin - 40)\n",
    "    text.setFont(\"Helvetica\", 12)\n",
    "    \n",
    "    # Wrap long lines\n",
    "    max_width = 80  # number of characters per line\n",
    "    wrapped_lines = []\n",
    "    for line in feedback.split(\"\\n\"):\n",
    "        wrapped_lines.extend(wrap(line, width=max_width))\n",
    "        wrapped_lines.append(\"\")  # blank line between sections\n",
    "\n",
    "    # Add lines to PDF\n",
    "    for line in wrapped_lines:\n",
    "        text.textLine(line)\n",
    "\n",
    "    c.drawText(text)\n",
    "    c.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "161c78f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AI Multi-Modal Interview Bot (Gemini) ===\n",
      "\n",
      "Generating interview questions...\n",
      "\n",
      "--- Interview Questions ---\n",
      "Describe the most technically challenging project you've worked on. What was your specific role, what were the major challenges, and how did you overcome them?\n",
      "\n",
      "Select Input Mode:\n",
      "1. Text\n",
      "2. Voice\n",
      "3. Image\n",
      "\n",
      "Evaluating your answer...\n",
      "\n",
      "--- AI Feedback ---\n",
      "This is an excellent, well-structured interview response. It's a prime example of how to answer a technical behavioral question effectively.\n",
      "\n",
      "### 1. Score: 9.5/10\n",
      "\n",
      "This is a top-tier answer that would impress almost any interviewer. It's clear, concise, technically detailed, and demonstrates strong problem-solving skills and ownership.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Strengths\n",
      "\n",
      "*   **Excellent Structure:** The response is perfectly structured, following a variant of the STAR method (Situation/Task, Action, Result) by explicitly breaking down Role, Challenges, Actions (How I Overcame Them), and Result. This makes it incredibly easy for the interviewer to follow and digest.\n",
      "*   **Specific Technical Details:** The candidate doesn't just say they \"solved a problem.\" They name specific technologies (Tkinter, Plotly), models (RandomForest), and techniques (buffering, threading with `after()` callbacks). This lends immense credibility and demonstrates genuine, hands-on experience.\n",
      "*   **Clear Problem-Solution Mapping:** The answer masterfully connects each challenge to a specific solution. For example:\n",
      "    *   **Challenge:** Resource-constrained environment. -> **Solution:** Used a lightweight RandomForest model.\n",
      "    *   **Challenge:** Tkinter's limitations. -> **Solution:** Embedded Plotly using HTML canvases.\n",
      "    *   **Challenge:** UI responsiveness. -> **Solution:** Applied threading with scheduled callbacks.\n",
      "*   **Demonstrates Ownership:** The use of \"I\" and phrases like \"I was the primary software engineer\" clearly communicates the candidate's role and contributions without taking undue credit.\n",
      "*   **Impactful Conclusion:** The final two sentences summarize the outcome and the project's significance, connecting it to broader engineering principles (\"software engineering best practices with AI integration and real-time system design\").\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Weaknesses\n",
      "\n",
      "It's difficult to find significant weaknesses, but to be critical, here are a few minor areas for polish:\n",
      "\n",
      "*   **Lack of Quantifiable Metrics:** The result is described with qualitative terms like \"successfully,\" \"real-time,\" and \"smooth.\" While effective, adding numbers would make the impact even more powerful. How much data was processed per second? What was the inference latency in milliseconds? What was the prediction accuracy?\n",
      "*   **No Mention of Collaboration:** The response is very \"I\"-focused. While great for showing ownership, most projects involve a team. A brief mention of collaboration (e.g., \"I worked with the data science team to select the right model\" or \"I coordinated with the hardware engineer to define the data protocol\") can demonstrate teamwork skills.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Improvement Tips\n",
      "\n",
      "To elevate this from a 9.5 to a perfect 10, the candidate could make these small additions:\n",
      "\n",
      "1.  **Quantify the Results:** Weave in specific numbers to make the success more tangible.\n",
      "    *   **Instead of:** \"...successfully processed live data, predicted suitable crops in real-time...\"\n",
      "    *   **Try:** \"...successfully processed data streams at 50Hz with under 0.1% packet loss, and our model made predictions in under 100ms, allowing for true real-time crop suitability analysis.\"\n",
      "\n",
      "2.  **Briefly Mention a Trade-off:** Great engineering involves making difficult choices. Mentioning one shows senior-level thinking.\n",
      "    *   **Example:** \"We specifically chose a RandomForest model over a more complex neural network. While the NN was slightly more accurate in offline tests, the RandomForest's inference speed was 10x faster, which was a critical trade-off for the resource-constrained hardware.\"\n",
      "\n",
      "3.  **Hint at Teamwork:** Add a short clause about working with others to round out the story.\n",
      "    *   **Example:** \"After aligning with the data scientist on the model requirements, I was responsible for embedding a lightweight RandomForest model...\"\n",
      "\n",
      "By incorporating these minor tweaks, the candidate would present a story that is not only technically impressive but also showcases a deep understanding of business impact, engineering trade-offs, and collaborative dynamics.\n",
      "\n",
      "âœ… Interview completed! Check 'Interview_Report.pdf' for details.\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# STEP 5: Main Logic\n",
    "# ==============================\n",
    "def main():\n",
    "    print(\"\\n=== AI Multi-Modal Interview Bot (Gemini) ===\")\n",
    "    role = input(\"Enter Job Role: \")\n",
    "\n",
    "    # Generate questions\n",
    "    print(\"\\nGenerating interview questions...\")\n",
    "    questions = generate_questions(role)\n",
    "    print(\"\\n--- Interview Questions ---\")\n",
    "    print(questions)\n",
    "\n",
    "    # Choose input mode\n",
    "    print(\"\\nSelect Input Mode:\")\n",
    "    print(\"1. Text\")\n",
    "    print(\"2. Voice\")\n",
    "    print(\"3. Image\")\n",
    "    choice = input(\"Enter choice (1/2/3): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        answer = get_text_input()\n",
    "    elif choice == \"2\":\n",
    "        answer = get_voice_input()\n",
    "    elif choice == \"3\":\n",
    "        answer = get_image_input()\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "        return\n",
    "\n",
    "    # Evaluate answer\n",
    "    print(\"\\nEvaluating your answer...\")\n",
    "    feedback = evaluate_answer(\"Sample Question\", answer)\n",
    "    print(\"\\n--- AI Feedback ---\")\n",
    "    print(feedback)\n",
    "\n",
    "    # Save PDF report\n",
    "    create_report(\"Interview_Report.pdf\", feedback)\n",
    "    print(\"\\nâœ… Interview completed! Check 'Interview_Report.pdf' for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c287be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AI Multi-Modal Interview Bot (Gemini) ===\n",
      "\n",
      "Generating interview questions...\n",
      "\n",
      "--- Interview Questions ---\n",
      "Describe the most complex technical project you've worked on. What were the biggest challenges, and how did you overcome them?\n",
      "\n",
      "Select Input Mode:\n",
      "1. Text\n",
      "2. Voice\n",
      "3. Image\n",
      "\n",
      "Evaluating your answer...\n",
      "\n",
      "--- AI Feedback ---\n",
      "This is an excellent interview response. It's well-structured, detailed, and effectively showcases a wide range of technical and problem-solving skills.\n",
      "\n",
      "### 1. Score: 9/10\n",
      "\n",
      "This is a top-tier answer that would impress in almost any technical interview. It's just shy of a perfect 10 because it lacks business context and quantifiable metrics, which would elevate it from a great technical story to a great engineering impact story.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Strengths\n",
      "\n",
      "*   **Excellent Structure:** The answer follows a clear and effective \"Problem -> Action -> Result\" (a variation of the STAR method) format. It explicitly calls out the \"Biggest Challenges\" and \"How I Overcame Them,\" which makes it incredibly easy for the interviewer to follow.\n",
      "*   **Demonstrates a Wide Skillset:** It effectively showcases expertise across multiple domains: hardware integration (sensors), real-time data processing, machine learning (model deployment), and desktop application development (Tkinter, UI/UX). This presents the candidate as a versatile and cross-functional engineer.\n",
      "*   **Specific and Technical:** The candidate uses specific technical terms correctly (buffering, serial communication, RandomForest, Plotly, HTML canvases, threading, `after()` event loop). This adds significant credibility and demonstrates genuine, hands-on experience, not just surface-level knowledge.\n",
      "*   **Strong Ownership:** The consistent use of \"I\" (\"I had to ensure,\" \"I optimized,\" \"I applied\") clearly communicates personal ownership and contribution to the project's success.\n",
      "*   **Focus on Problem-Solving:** The answer isn't just a list of things the candidate did; it's a narrative about overcoming concrete, difficult challenges. This is exactly what interviewers are looking for.\n",
      "*   **Impactful Conclusion:** It ends with a strong summary of the final result and a reflection on personal growth (\"strengthened my ability to solve cross-disciplinary technical problems\"), which is a polished way to conclude.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Weaknesses\n",
      "\n",
      "*   **Lack of Business Context:** The response is entirely technical. It doesn't explain *why* this system was needed. Was it for predictive maintenance to save a company money? Was it for a scientific experiment? Adding one sentence of context at the beginning would ground the project in a real-world purpose.\n",
      "*   **No Quantifiable Results:** The results are described qualitatively (\"responsive dashboard,\" \"predicted outcomes in real-time\"). The answer would be even more powerful with metrics. For example:\n",
      "    *   What was the data processing latency? (e.g., \"processed sensor data with under 100ms of latency\")\n",
      "    *   How accurate was the model? (e.g., \"achieved 98% prediction accuracy\")\n",
      "    *   What was the impact? (e.g., \"which led to a 15% reduction in system failures\")\n",
      "*   **No Mention of Teamwork:** While strong \"I\" statements are good, complex projects usually involve collaboration. A brief mention of working with others (e.g., \"I worked with a data scientist to select the model\" or \"I gathered UI requirements from the end-users\") can demonstrate teamwork skills without diminishing personal contribution.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Improvement Tips\n",
      "\n",
      "To turn this 9/10 into a 10/10, consider these small but powerful additions:\n",
      "\n",
      "1.  **Start with the \"Why\".**\n",
      "    *   **Before:** \"The most complex technical project I worked on was...\"\n",
      "    *   **Improved:** \"At my previous role, we needed to prevent unexpected equipment failures. My most complex project was building a real-time AI-driven monitoring system to predict those failures before they happened. The system combined...\"\n",
      "\n",
      "2.  **Add Quantifiable Metrics to the Results.**\n",
      "    *   **Before:** \"...predicted outcomes in real-time, and displayed results in a responsive dashboard.\"\n",
      "    *   **Improved:** \"...predicted outcomes with 95% accuracy and displayed the results on a responsive dashboard that updated every second without freezing. This new system allowed us to preemptively address 80% of critical failures.\"\n",
      "\n",
      "3.  **Subtly Weave in Collaboration.**\n",
      "    *   **Improved:** \"To keep predictions fast, I collaborated with our data scientist to select a lightweight RandomForest model...\" or \"For visualization, I worked with the primary users to understand their needs, which led me to integrate Plotly charts...\"\n",
      "\n",
      "**Revised Example Incorporating Improvements:**\n",
      "\n",
      "> \"My most complex technical project was developing a predictive maintenance system to reduce costly equipment downtime. The goal was to combine hardware sensors, machine learning, and a desktop application to monitor operations in real-time.\n",
      ">\n",
      "> **The biggest challenges were:**\n",
      "> 1.  **Real-time Data Processing:** Sensor data was streaming in at 50Hz, and we couldn't afford any data loss.\n",
      "> 2.  **Model Deployment:** Integrating our ML model required balancing a 95%+ accuracy target with sub-second prediction speed.\n",
      "> 3.  **Visualization & Concurrency:** The primary users needed a modern dashboard, but the core application was built in Tkinter. It had to handle data collection, prediction, and UI updates simultaneously without freezing.\n",
      ">\n",
      "> **To overcome these, I:**\n",
      "> 1.  Optimized the data pipeline with double buffering and robust error handling for the serial communication.\n",
      "> 2.  Worked with our data scientist to select and deploy a lightweight RandomForest model, which I integrated using an efficient pre-processing pipeline.\n",
      "> 3.  For the UI, I embedded Plotly charts into Tkinter using an HTML canvas, giving us modern, interactive dashboards. I then used Python's threading and Tkinterâ€™s `after()` event loop to schedule UI updates safely from the data processing thread, which solved the freezing issues.\n",
      ">\n",
      "> **The result was a stable system that processed sensor data continuously, predicted failures with 96% accuracy, and displayed results on a responsive dashboard. It ultimately helped reduce critical equipment downtime by over 20% in the first quarter.\"**\n",
      "\n",
      "âœ… Interview completed! Check 'Interview_Report.pdf' for details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Gemini API Key\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Configure Gemini API\n",
    "genai.configure(api_key=api_key)\n",
    "# ==============================\n",
    "# STEP 2: Gemini Functions\n",
    "# ==============================\n",
    "def generate_questions(role):\n",
    "    \"\"\"Generate interview questions using Gemini\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an interviewer. Generate 1 technical or behavioral interview questions\n",
    "    for a candidate applying for {role}. Only return the list of questions as plain text, no explanation.\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def evaluate_answer(question, answer):\n",
    "    \"\"\"Evaluate candidate answer using Gemini\"\"\"\n",
    "\n",
    "    # Ensure inputs are not empty\n",
    "    if not question.strip() or not answer.strip():\n",
    "        return \"âš ï¸ Question or Answer is empty. Please provide valid input.\"\n",
    "\n",
    "    # Prompt to send to Gemini\n",
    "    eval_prompt = f\"\"\"\n",
    "    Evaluate this interview response:\n",
    "    Question: {question}\n",
    "    Answer: {answer}\n",
    "\n",
    "    Provide:\n",
    "    1. Score out of 10\n",
    "    2. Strengths\n",
    "    3. Weaknesses\n",
    "    4. Improvement Tips\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize model\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.generate_content(eval_prompt)\n",
    "\n",
    "    # Safely access model output\n",
    "    if response.candidates and response.candidates[0].content.parts:\n",
    "        return response.candidates[0].content.parts[0].text\n",
    "    else:\n",
    "        return \"âš ï¸ No feedback was generated by the model. Try rephrasing your answer.\"\n",
    "    \n",
    "    # ==============================\n",
    "# STEP 3: Input Modes\n",
    "# ==============================\n",
    "def get_text_input():\n",
    "    return input(\"Type your answer: \")\n",
    "\n",
    "def get_voice_input():\n",
    "    \"\"\"Capture voice and convert to text\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"ðŸŽ¤ Speak now...\")\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        return r.recognize_google(audio)\n",
    "    except:\n",
    "        return \"Could not understand audio.\"\n",
    "\n",
    "def get_image_input():\n",
    "    \"\"\"Extract text from image using OCR\"\"\"\n",
    "    image_path = input(\"Enter image file path: \")\n",
    "    img = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(img)\n",
    "\n",
    "# ==============================\n",
    "# STEP 4: PDF Report\n",
    "# ==============================\n",
    "\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from textwrap import wrap\n",
    "\n",
    "def create_report(filename, feedback):\n",
    "    c = canvas.Canvas(filename, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Margins\n",
    "    left_margin = 50\n",
    "    top_margin = height - 50\n",
    "    \n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(left_margin, top_margin, \"AI Interview Feedback Report\")\n",
    "    \n",
    "    # Prepare text object\n",
    "    text = c.beginText()\n",
    "    text.setTextOrigin(left_margin, top_margin - 40)\n",
    "    text.setFont(\"Helvetica\", 12)\n",
    "    \n",
    "    # Wrap long lines\n",
    "    max_width = 80  # number of characters per line\n",
    "    wrapped_lines = []\n",
    "    for line in feedback.split(\"\\n\"):\n",
    "        wrapped_lines.extend(wrap(line, width=max_width))\n",
    "        wrapped_lines.append(\"\")  # blank line between sections\n",
    "\n",
    "    # Add lines to PDF\n",
    "    for line in wrapped_lines:\n",
    "        text.textLine(line)\n",
    "\n",
    "    c.drawText(text)\n",
    "    c.save()\n",
    "\n",
    "# ==============================\n",
    "# STEP 5: Main Logic\n",
    "# ==============================\n",
    "def main():\n",
    "    print(\"\\n=== AI Multi-Modal Interview Bot (Gemini) ===\")\n",
    "    role = input(\"Enter Job Role: \")\n",
    "\n",
    "    # Generate questions\n",
    "    print(\"\\nGenerating interview questions...\")\n",
    "    questions = generate_questions(role)\n",
    "    print(\"\\n--- Interview Questions ---\")\n",
    "    print(questions)\n",
    "\n",
    "    # Choose input mode\n",
    "    print(\"\\nSelect Input Mode:\")\n",
    "    print(\"1. Text\")\n",
    "    print(\"2. Voice\")\n",
    "    print(\"3. Image\")\n",
    "    choice = input(\"Enter choice (1/2/3): \")\n",
    "\n",
    "    if choice == \"1\":\n",
    "        answer = get_text_input()\n",
    "    elif choice == \"2\":\n",
    "        answer = get_voice_input()\n",
    "    elif choice == \"3\":\n",
    "        answer = get_image_input()\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "        return\n",
    "\n",
    "    # Evaluate answer\n",
    "    print(\"\\nEvaluating your answer...\")\n",
    "    feedback = evaluate_answer(\"Sample Question\", answer)\n",
    "    print(\"\\n--- AI Feedback ---\")\n",
    "    print(feedback)\n",
    "\n",
    "    # Save PDF report\n",
    "    create_report(\"Interview_Report.pdf\", feedback)\n",
    "    print(\"\\nâœ… Interview completed! Check 'Interview_Report.pdf' for details.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4e7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
